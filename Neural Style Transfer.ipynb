{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "66396160/80134624 [=======================>......] - ETA: 10:40"
     ]
    }
   ],
   "source": [
    "model = VGG19(\n",
    "    include_top =False,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "model.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.appliactions.vgg19 import preprocess_input\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_image(image_path):\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)      # to make image compatible with our VGG model\n",
    "    img = np.expand_dims(img, axis =0)    # to convert to it to 4 dimensional\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(x):\n",
    "    #Opposite of preprocess_input()\n",
    "    x[:,:,0] += 103.939\n",
    "    x[:,:,1] += 116.779\n",
    "    x[:,:,2] += 123.68\n",
    "    x = x[:,:,::-1]     # change order of channels\n",
    "    x = np.clip(x, 0, 255).astype('uint8')    # scale values between 0 to 255\n",
    "    return x\n",
    "\n",
    "def display_image(image):\n",
    "    if len(image.shape) == 4:\n",
    "        img = np.squeeze(image, axis = 0)   # opposite of expand_dims()\n",
    "    img = deprocess(img)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content Image\n",
    "display_image(load_and_process_image('profile_white_background.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style Image\n",
    "display_image(load_and_process_image('style.jpeg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content and style Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = 'block5_conv2'       # deep layer\n",
    "\n",
    "# shallow layer\n",
    "style_layers = [\n",
    "    'block1_conv1',\n",
    "    'block3_conv1',\n",
    "    'block5_conv1'\n",
    "]\n",
    "\n",
    "content_Model = Model(\n",
    "    inputs = model.input,\n",
    "    outputs = model.get_layer(content_layer)\n",
    ")\n",
    "\n",
    "style_models = [Model(inputs = model.input,\n",
    "                     outputs = model.get_layer(layer).output for layer in style_layers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_cost(content, generated):\n",
    "    a_C = content_model(content)\n",
    "    a_G = content_model(generated)\n",
    "    cost = tf.reduce_mean(tf.sqaure(a_C -a_G))    # mean square difference\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
